{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee07fc7",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Required Libraries\n",
    "\n",
    "**Interview Explanation:**\n",
    "- **Pandas**: Data manipulation and analysis\n",
    "- **NumPy**: Numerical operations\n",
    "- **Matplotlib & Seaborn**: Data visualization\n",
    "- **Datetime**: Time-series data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Time and date handling\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9946a",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load the Dataset\n",
    "\n",
    "**Interview Explanation:**\n",
    "- Loading the raw energy dataset\n",
    "- Displaying first few rows to understand structure\n",
    "- Checking basic information about columns and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e722580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_raw = pd.read_csv('energy_dataset.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df_raw.shape[0]} rows, {df_raw.shape[1]} columns\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names for better understanding\n",
    "print(\"\\nColumn Names:\")\n",
    "print(\"=\"*50)\n",
    "for i, col in enumerate(df_raw.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f3a91",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Cleaning & Preprocessing\n",
    "\n",
    "**Interview Explanation:**\n",
    "This is a critical step where we:\n",
    "1. **Convert time column** to proper datetime format for time-series analysis\n",
    "2. **Handle missing values** - Check percentage and decide strategy\n",
    "3. **Remove duplicates** - Ensure data quality\n",
    "4. **Select relevant columns** - Focus on consumption and generation data\n",
    "5. **Create new features** - Extract hour, day, month for trend analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a working copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"Step 1: Working copy created\")\n",
    "print(f\"Original dataset preserved with {df_raw.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert time column to datetime\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "\n",
    "# Set time as index for time-series analysis\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "print(\"Step 2: Time column converted to datetime\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Total duration: {(df.index.max() - df.index.min()).days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d691ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Check for missing values\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Step 3: Missing Values Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal missing values: {total_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Step 4: Found {duplicates} duplicate rows\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Removed {duplicates} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2511839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Select relevant columns\n",
    "# Removing forecast columns and price columns for this analysis\n",
    "# Focus on actual generation and consumption\n",
    "\n",
    "columns_to_drop = [\n",
    "    'forecast solar day ahead',\n",
    "    'forecast wind offshore eday ahead', \n",
    "    'forecast wind onshore day ahead',\n",
    "    'total load forecast',\n",
    "    'price day ahead',\n",
    "    'price actual',\n",
    "    'generation hydro pumped storage aggregated',\n",
    "    'generation fossil coal-derived gas',  # Has many missing values\n",
    "    'generation fossil oil shale',  # Has many missing values\n",
    "    'generation fossil peat',  # Has many missing values\n",
    "    'generation geothermal',  # Has many missing values\n",
    "    'generation marine'  # Has many missing values\n",
    "]\n",
    "\n",
    "df_clean = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "print(\"Step 5: Removed irrelevant and high-missing columns\")\n",
    "print(f\"Columns reduced from {df.shape[1]} to {df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Handle remaining missing values using forward fill\n",
    "# For time-series data, forward fill is appropriate as energy patterns are continuous\n",
    "\n",
    "before_fill = df_clean.isnull().sum().sum()\n",
    "df_clean = df_clean.fillna(method='ffill').fillna(method='bfill')\n",
    "after_fill = df_clean.isnull().sum().sum()\n",
    "\n",
    "print(\"Step 6: Missing values handled\")\n",
    "print(f\"Missing values before: {before_fill}\")\n",
    "print(f\"Missing values after: {after_fill}\")\n",
    "print(\"\\nâœ“ Data cleaning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92455296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Feature Engineering - Extract time-based features\n",
    "# These features help identify patterns in energy consumption\n",
    "\n",
    "df_clean['Year'] = df_clean.index.year\n",
    "df_clean['Month'] = df_clean.index.month\n",
    "df_clean['Day'] = df_clean.index.day\n",
    "df_clean['Hour'] = df_clean.index.hour\n",
    "df_clean['DayOfWeek'] = df_clean.index.dayofweek  # Monday=0, Sunday=6\n",
    "df_clean['DayName'] = df_clean.index.day_name()\n",
    "df_clean['MonthName'] = df_clean.index.month_name()\n",
    "df_clean['Quarter'] = df_clean.index.quarter\n",
    "\n",
    "# Classify time of day\n",
    "def classify_time(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df_clean['TimeOfDay'] = df_clean['Hour'].apply(classify_time)\n",
    "\n",
    "# Weekend flag\n",
    "df_clean['IsWeekend'] = df_clean['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"Step 7: Time-based features created\")\n",
    "print(\"\\nNew features:\")\n",
    "print(\"- Year, Month, Day, Hour\")\n",
    "print(\"- DayOfWeek, DayName, MonthName\")\n",
    "print(\"- Quarter, TimeOfDay, IsWeekend\")\n",
    "print(f\"\\nFinal dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataset summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANED DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219eeb8",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Interview Explanation:**\n",
    "EDA helps us understand:\n",
    "- **Distribution** of energy consumption\n",
    "- **Statistical summary** of all variables\n",
    "- **Correlations** between different energy sources\n",
    "- **Trends** over time\n",
    "- **Patterns** in consumption behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"Statistical Summary of Energy Data:\")\n",
    "print(\"=\"*70)\n",
    "df_clean.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bba1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Overall Energy Consumption Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_clean['total load actual'], bins=50, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Energy Load (MW)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Total Energy Load', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df_clean['total load actual'], vert=True)\n",
    "plt.ylabel('Energy Load (MW)', fontsize=12)\n",
    "plt.title('Boxplot of Total Energy Load', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Load: {df_clean['total load actual'].mean():.2f} MW\")\n",
    "print(f\"Median Load: {df_clean['total load actual'].median():.2f} MW\")\n",
    "print(f\"Max Load: {df_clean['total load actual'].max():.2f} MW\")\n",
    "print(f\"Min Load: {df_clean['total load actual'].min():.2f} MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Energy Generation by Source\n",
    "generation_columns = [\n",
    "    'generation biomass',\n",
    "    'generation fossil brown coal/lignite',\n",
    "    'generation fossil gas',\n",
    "    'generation fossil hard coal',\n",
    "    'generation fossil oil',\n",
    "    'generation hydro pumped storage consumption',\n",
    "    'generation hydro run-of-river and poundage',\n",
    "    'generation hydro water reservoir',\n",
    "    'generation nuclear',\n",
    "    'generation other',\n",
    "    'generation other renewable',\n",
    "    'generation solar',\n",
    "    'generation waste',\n",
    "    'generation wind offshore',\n",
    "    'generation wind onshore'\n",
    "]\n",
    "\n",
    "# Calculate total generation for each source\n",
    "generation_totals = df_clean[generation_columns].sum().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(generation_totals)))\n",
    "bars = plt.bar(range(len(generation_totals)), generation_totals.values, color=colors)\n",
    "plt.xticks(range(len(generation_totals)), \n",
    "           [col.replace('generation ', '') for col in generation_totals.index], \n",
    "           rotation=45, ha='right')\n",
    "plt.xlabel('Energy Source', fontsize=12)\n",
    "plt.ylabel('Total Generation (MW)', fontsize=12)\n",
    "plt.title('Total Energy Generation by Source', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Energy Sources:\")\n",
    "for i, (source, value) in enumerate(generation_totals.head().items(), 1):\n",
    "    print(f\"{i}. {source.replace('generation ', '').title()}: {value:,.0f} MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Renewable vs Non-Renewable Energy\n",
    "renewable_sources = [\n",
    "    'generation biomass',\n",
    "    'generation hydro run-of-river and poundage',\n",
    "    'generation hydro water reservoir',\n",
    "    'generation other renewable',\n",
    "    'generation solar',\n",
    "    'generation wind offshore',\n",
    "    'generation wind onshore'\n",
    "]\n",
    "\n",
    "non_renewable_sources = [\n",
    "    'generation fossil brown coal/lignite',\n",
    "    'generation fossil gas',\n",
    "    'generation fossil hard coal',\n",
    "    'generation fossil oil',\n",
    "    'generation nuclear'\n",
    "]\n",
    "\n",
    "df_clean['Total_Renewable'] = df_clean[renewable_sources].sum(axis=1)\n",
    "df_clean['Total_NonRenewable'] = df_clean[non_renewable_sources].sum(axis=1)\n",
    "\n",
    "renewable_total = df_clean['Total_Renewable'].sum()\n",
    "non_renewable_total = df_clean['Total_NonRenewable'].sum()\n",
    "\n",
    "# Pie chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sizes = [renewable_total, non_renewable_total]\n",
    "labels = ['Renewable', 'Non-Renewable']\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "explode = (0.05, 0)\n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90, textprops={'fontsize': 14, 'fontweight': 'bold'})\n",
    "plt.title('Renewable vs Non-Renewable Energy Generation', fontsize=16, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRenewable Energy: {renewable_total:,.0f} MW ({renewable_total/(renewable_total+non_renewable_total)*100:.1f}%)\")\n",
    "print(f\"Non-Renewable Energy: {non_renewable_total:,.0f} MW ({non_renewable_total/(renewable_total+non_renewable_total)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ff8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Time Series Plot - Overall Consumption Trend\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df_clean.index, df_clean['total load actual'], linewidth=0.5, color='darkblue', alpha=0.7)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Total Load (MW)', fontsize=12)\n",
    "plt.title('Energy Consumption Over Time (2015-2018)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Observations:\")\n",
    "print(\"- Seasonal patterns are visible\")\n",
    "print(\"- Regular cyclical variations indicate daily/weekly patterns\")\n",
    "print(\"- No significant missing data gaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3643fe8",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Peak Consumption Analysis\n",
    "\n",
    "**Interview Explanation:**\n",
    "Identifying peak hours helps:\n",
    "- **Grid Management**: Plan capacity during high-demand periods\n",
    "- **Cost Optimization**: Implement dynamic pricing\n",
    "- **Resource Allocation**: Schedule maintenance during low-demand hours\n",
    "- **Business Strategy**: Target energy-saving campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Average Load by Hour of Day\n",
    "hourly_avg = df_clean.groupby('Hour')['total load actual'].mean()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "bars = plt.bar(hourly_avg.index, hourly_avg.values, color='coral', edgecolor='black')\n",
    "# Highlight peak hour\n",
    "peak_hour = hourly_avg.idxmax()\n",
    "bars[peak_hour].set_color('red')\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Average Load (MW)', fontsize=12)\n",
    "plt.title('Average Energy Consumption by Hour', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(24))\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Line plot for better trend visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2, markersize=8, color='darkgreen')\n",
    "plt.axvline(x=peak_hour, color='red', linestyle='--', linewidth=2, label=f'Peak Hour: {peak_hour}:00')\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Average Load (MW)', fontsize=12)\n",
    "plt.title('Hourly Consumption Trend', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(24))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š PEAK HOUR ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Peak Hour: {peak_hour}:00 ({hourly_avg[peak_hour]:.2f} MW)\")\n",
    "print(f\"Lowest Hour: {hourly_avg.idxmin()}:00 ({hourly_avg.min():.2f} MW)\")\n",
    "print(f\"Difference: {hourly_avg[peak_hour] - hourly_avg.min():.2f} MW\")\n",
    "\n",
    "# Identify peak hours (above 95th percentile)\n",
    "threshold = hourly_avg.quantile(0.85)\n",
    "peak_hours = hourly_avg[hourly_avg >= threshold].index.tolist()\n",
    "print(f\"\\nPeak Hours (Top 15%): {peak_hours}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Average Load by Day of Week\n",
    "daily_avg = df_clean.groupby('DayName')['total load actual'].mean()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_avg = daily_avg.reindex(day_order)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors_day = ['green' if day in ['Saturday', 'Sunday'] else 'steelblue' for day in day_order]\n",
    "plt.bar(range(7), daily_avg.values, color=colors_day, edgecolor='black')\n",
    "plt.xticks(range(7), day_order, rotation=45)\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Average Load (MW)', fontsize=12)\n",
    "plt.title('Average Energy Consumption by Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.legend(['Weekday', 'Weekend'], loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“… DAILY PATTERN ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "for day, load in daily_avg.items():\n",
    "    print(f\"{day}: {load:.2f} MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Weekday vs Weekend Comparison\n",
    "weekday_avg = df_clean[df_clean['IsWeekend'] == 0]['total load actual'].mean()\n",
    "weekend_avg = df_clean[df_clean['IsWeekend'] == 1]['total load actual'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "categories = ['Weekday', 'Weekend']\n",
    "values = [weekday_avg, weekend_avg]\n",
    "colors = ['#3498db', '#2ecc71']\n",
    "bars = plt.bar(categories, values, color=colors, edgecolor='black', width=0.6)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{value:.0f} MW',\n",
    "             ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.ylabel('Average Load (MW)', fontsize=12)\n",
    "plt.title('Weekday vs Weekend Energy Consumption', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, max(values) * 1.1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "difference = weekday_avg - weekend_avg\n",
    "percent_diff = (difference / weekday_avg) * 100\n",
    "print(f\"\\nðŸ“ˆ WEEKDAY VS WEEKEND COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Weekday Average: {weekday_avg:.2f} MW\")\n",
    "print(f\"Weekend Average: {weekend_avg:.2f} MW\")\n",
    "print(f\"Difference: {difference:.2f} MW ({percent_diff:.2f}% lower on weekends)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033eefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Monthly Consumption Pattern\n",
    "monthly_avg = df_clean.groupby('MonthName')['total load actual'].mean()\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "monthly_avg = monthly_avg.reindex(month_order)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "colors_month = plt.cm.coolwarm(np.linspace(0, 1, 12))\n",
    "plt.bar(range(12), monthly_avg.values, color=colors_month, edgecolor='black')\n",
    "plt.xticks(range(12), [m[:3] for m in month_order], rotation=0)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Average Load (MW)', fontsize=12)\n",
    "plt.title('Average Energy Consumption by Month', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“† MONTHLY PATTERN ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Highest Consumption: {monthly_avg.idxmax()} ({monthly_avg.max():.2f} MW)\")\n",
    "print(f\"Lowest Consumption: {monthly_avg.idxmin()} ({monthly_avg.min():.2f} MW)\")\n",
    "print(\"\\nObservation: Higher consumption in winter months (heating) and summer months (cooling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4560cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Heatmap: Hour vs Day of Week\n",
    "heatmap_data = df_clean.pivot_table(\n",
    "    values='total load actual',\n",
    "    index='Hour',\n",
    "    columns='DayName',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "heatmap_data = heatmap_data[day_order]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(heatmap_data, annot=False, fmt='.0f', cmap='YlOrRd', cbar_kws={'label': 'Load (MW)'})\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Hour of Day', fontsize=12)\n",
    "plt.title('Energy Consumption Heatmap: Hour vs Day', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”¥ HEATMAP INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"- Darker colors indicate higher consumption\")\n",
    "print(\"- Clear pattern of peak hours (9-20) visible\")\n",
    "print(\"- Weekend consumption lower than weekdays\")\n",
    "print(\"- Night hours (0-6) show lowest consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78329741",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Business Insights & KPIs\n",
    "\n",
    "**Interview Explanation:**\n",
    "These KPIs are crucial for business decision-making:\n",
    "- **Total Load**: Overall energy demand\n",
    "- **Peak Load**: Maximum capacity required\n",
    "- **Average Load**: Baseline operations\n",
    "- **Load Factor**: Efficiency metric (Average/Peak ratio)\n",
    "- **Renewable Percentage**: Sustainability metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3476265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Key Performance Indicators (KPIs)\n",
    "total_load = df_clean['total load actual'].sum()\n",
    "peak_load = df_clean['total load actual'].max()\n",
    "average_load = df_clean['total load actual'].mean()\n",
    "min_load = df_clean['total load actual'].min()\n",
    "load_factor = (average_load / peak_load) * 100\n",
    "\n",
    "renewable_percentage = (renewable_total / (renewable_total + non_renewable_total)) * 100\n",
    "\n",
    "# Growth analysis\n",
    "yearly_avg = df_clean.groupby('Year')['total load actual'].mean()\n",
    "yearly_growth = yearly_avg.pct_change() * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY PERFORMANCE INDICATORS (KPIs)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š LOAD METRICS:\")\n",
    "print(f\"   Total Load: {total_load:,.0f} MW\")\n",
    "print(f\"   Peak Load: {peak_load:,.0f} MW\")\n",
    "print(f\"   Average Load: {average_load:,.0f} MW\")\n",
    "print(f\"   Minimum Load: {min_load:,.0f} MW\")\n",
    "print(f\"   Load Factor: {load_factor:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸŒ± SUSTAINABILITY METRICS:\")\n",
    "print(f\"   Renewable Energy: {renewable_percentage:.2f}%\")\n",
    "print(f\"   Non-Renewable Energy: {100-renewable_percentage:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ YEAR-OVER-YEAR GROWTH:\")\n",
    "for year in yearly_avg.index:\n",
    "    print(f\"   {year}: {yearly_avg[year]:,.0f} MW\", end=\"\")\n",
    "    if year in yearly_growth.index and not pd.isna(yearly_growth[year]):\n",
    "        print(f\" ({yearly_growth[year]:+.2f}% vs previous year)\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "print(f\"\\nâš¡ PEAK INSIGHTS:\")\n",
    "print(f\"   Peak Hour: {peak_hour}:00\")\n",
    "print(f\"   Peak Day: {daily_avg.idxmax()}\")\n",
    "print(f\"   Peak Month: {monthly_avg.idxmax()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d36d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Recommendations Dashboard\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recommendations = [\n",
    "    \"1. PEAK DEMAND MANAGEMENT:\\n\"\n",
    "    f\"   - Peak consumption occurs at {peak_hour}:00\\n\"\n",
    "    \"   - Implement demand response programs during peak hours\\n\"\n",
    "    \"   - Consider dynamic pricing to shift load to off-peak hours\\n\",\n",
    "    \n",
    "    \"2. RENEWABLE ENERGY OPTIMIZATION:\\n\"\n",
    "    f\"   - Current renewable energy: {renewable_percentage:.1f}%\\n\"\n",
    "    f\"   - Target: Increase to {renewable_percentage + 10:.1f}% in next year\\n\"\n",
    "    \"   - Invest in solar/wind capacity during low-generation periods\\n\",\n",
    "    \n",
    "    \"3. OPERATIONAL EFFICIENCY:\\n\"\n",
    "    f\"   - Load Factor: {load_factor:.1f}% indicates room for improvement\\n\"\n",
    "    \"   - Schedule maintenance during low-demand hours (2 AM - 5 AM)\\n\"\n",
    "    \"   - Optimize grid operations during weekend (lower demand)\\n\",\n",
    "    \n",
    "    \"4. SEASONAL PLANNING:\\n\"\n",
    "    f\"   - Highest demand: {monthly_avg.idxmax()}\\n\"\n",
    "    \"   - Prepare additional capacity for summer/winter peaks\\n\"\n",
    "    \"   - Promote energy conservation campaigns in high-demand months\\n\",\n",
    "    \n",
    "    \"5. COST OPTIMIZATION:\\n\"\n",
    "    \"   - Weekday demand is higher than weekend\\n\"\n",
    "    \"   - Implement time-of-use pricing strategies\\n\"\n",
    "    \"   - Encourage industrial users to shift operations to off-peak times\\n\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8ed5d",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Export Data for Power BI Dashboard\n",
    "\n",
    "**Interview Explanation:**\n",
    "We export multiple CSV files for Power BI:\n",
    "1. **Complete cleaned dataset** - Full historical data\n",
    "2. **Daily aggregates** - For daily trend analysis\n",
    "3. **Hourly aggregates** - For intraday patterns\n",
    "4. **Monthly aggregates** - For long-term trends\n",
    "5. **KPI summary** - For dashboard cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4388bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Export complete cleaned dataset\n",
    "df_clean_export = df_clean.copy()\n",
    "df_clean_export.reset_index(inplace=True)\n",
    "df_clean_export.to_csv('cleaned_energy_data.csv', index=False)\n",
    "print(\"âœ“ Exported: cleaned_energy_data.csv\")\n",
    "print(f\"  Rows: {len(df_clean_export)}, Columns: {len(df_clean_export.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1af0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Export daily aggregates\n",
    "daily_summary = df_clean.groupby(df_clean.index.date).agg({\n",
    "    'total load actual': ['sum', 'mean', 'max', 'min'],\n",
    "    'Total_Renewable': 'sum',\n",
    "    'Total_NonRenewable': 'sum',\n",
    "    'generation solar': 'sum',\n",
    "    'generation wind onshore': 'sum',\n",
    "    'generation wind offshore': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "daily_summary.columns = ['Date', 'Total_Load', 'Avg_Load', 'Peak_Load', 'Min_Load',\n",
    "                         'Renewable_Gen', 'NonRenewable_Gen', 'Solar_Gen', \n",
    "                         'Wind_Onshore_Gen', 'Wind_Offshore_Gen']\n",
    "\n",
    "daily_summary.to_csv('daily_energy_summary.csv', index=False)\n",
    "print(\"âœ“ Exported: daily_energy_summary.csv\")\n",
    "print(f\"  Rows: {len(daily_summary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4539e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Export hourly pattern data\n",
    "hourly_pattern = df_clean.groupby(['Hour', 'DayName']).agg({\n",
    "    'total load actual': 'mean',\n",
    "    'Total_Renewable': 'mean',\n",
    "    'Total_NonRenewable': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "hourly_pattern.columns = ['Hour', 'Day', 'Avg_Load', 'Avg_Renewable', 'Avg_NonRenewable']\n",
    "hourly_pattern.to_csv('hourly_pattern.csv', index=False)\n",
    "print(\"âœ“ Exported: hourly_pattern.csv\")\n",
    "print(f\"  Rows: {len(hourly_pattern)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Export monthly summary\n",
    "monthly_summary = df_clean.groupby(['Year', 'MonthName']).agg({\n",
    "    'total load actual': ['sum', 'mean', 'max'],\n",
    "    'Total_Renewable': 'sum',\n",
    "    'Total_NonRenewable': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_summary.columns = ['Year', 'Month', 'Total_Load', 'Avg_Load', 'Peak_Load',\n",
    "                           'Renewable_Gen', 'NonRenewable_Gen']\n",
    "\n",
    "monthly_summary.to_csv('monthly_energy_summary.csv', index=False)\n",
    "print(\"âœ“ Exported: monthly_energy_summary.csv\")\n",
    "print(f\"  Rows: {len(monthly_summary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Export KPI summary for Power BI cards\n",
    "kpi_data = pd.DataFrame({\n",
    "    'Metric': ['Total Load (MW)', 'Peak Load (MW)', 'Average Load (MW)', \n",
    "               'Load Factor (%)', 'Renewable Energy (%)', 'Peak Hour',\n",
    "               'Peak Day', 'Peak Month'],\n",
    "    'Value': [f\"{total_load:,.0f}\", f\"{peak_load:,.0f}\", f\"{average_load:,.0f}\",\n",
    "              f\"{load_factor:.2f}\", f\"{renewable_percentage:.2f}\", \n",
    "              f\"{peak_hour}:00\", daily_avg.idxmax(), monthly_avg.idxmax()]\n",
    "})\n",
    "\n",
    "kpi_data.to_csv('kpi_summary.csv', index=False)\n",
    "print(\"âœ“ Exported: kpi_summary.csv\")\n",
    "print(f\"  Rows: {len(kpi_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all exported files\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTED FILES SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFiles ready for Power BI Dashboard:\")\n",
    "print(\"1. cleaned_energy_data.csv - Complete dataset with all features\")\n",
    "print(\"2. daily_energy_summary.csv - Daily aggregates for trend analysis\")\n",
    "print(\"3. hourly_pattern.csv - Hourly patterns by day of week\")\n",
    "print(\"4. monthly_energy_summary.csv - Monthly summaries for YoY comparison\")\n",
    "print(\"5. kpi_summary.csv - Key metrics for dashboard cards\")\n",
    "print(\"\\nâœ“ All files exported successfully!\")\n",
    "print(\"\\nNext Step: Import these CSVs into Power BI to create visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b019e",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Project Summary & Key Findings\n",
    "\n",
    "### Key Achievements:\n",
    "1. âœ“ Cleaned and preprocessed 35,000+ energy consumption records\n",
    "2. âœ“ Handled missing values using forward-fill imputation\n",
    "3. âœ“ Engineered 10+ time-based features for analysis\n",
    "4. âœ“ Identified peak consumption patterns and trends\n",
    "5. âœ“ Generated actionable business insights\n",
    "6. âœ“ Prepared data exports for Power BI dashboard\n",
    "\n",
    "### Technical Skills Demonstrated:\n",
    "- **Python**: Pandas, NumPy, Matplotlib, Seaborn\n",
    "- **Data Cleaning**: Missing value handling, duplicate removal, data type conversion\n",
    "- **Feature Engineering**: Time-based features, aggregations, categorical encoding\n",
    "- **EDA**: Statistical analysis, visualization, pattern identification\n",
    "- **Business Intelligence**: KPI calculation, insights generation, data export\n",
    "\n",
    "### Next Steps:\n",
    "1. Create Power BI dashboard with interactive visualizations\n",
    "2. Implement predictive models for load forecasting\n",
    "3. Deploy as web application for stakeholder access"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
